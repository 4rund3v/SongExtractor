{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import imutils\n",
    "import numpy as np\n",
    "from imutils.object_detection import non_max_suppression\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset =[ os.path.join(\"data\", i) for i in os.listdir(\"data\") ]\n",
    "print(\"Total number of images in the dataset : {}\".format(len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_image = cv2.imread(dataset[0])\n",
    "cv2.namedWindow(\"Base Image\", cv2.WINDOW_NORMAL) # to create an window and then populate it with the image\n",
    "# WINDOW_NORMAL : in order to allow for the resizing of the window thats displayed.\n",
    "cv2.imshow(\"Base Image\", base_image) \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "base_image.shape # this is the resolution of the image, (height,width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# East  detector model will be used for the detection of the text from the screen\n",
    "# this requires that the image width  & height to be a multiple of 32\n",
    "# So image will be resized to 1920 and 1280\n",
    "resized_image = cv2.resize(base_image, (1280, 1984))\n",
    "resized_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.namedWindow(\"Resized Image\", cv2.WINDOW_NORMAL) # to create an window and then populate it with the image\n",
    "# WINDOW_NORMAL : in order to allow for the resizing of the window thats displayed.\n",
    "cv2.imshow(\"Resized Image\", resized_image) \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_height, orig_width = base_image.shape[:2]\n",
    "new_height, new_width = resized_image.shape[:2]\n",
    "width_ratio = orig_width/float(new_width)\n",
    "heigth_ratio = orig_height/float(new_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below are the two layers that we are intrested in :\n",
    "#  one to get the probabilities and the\n",
    "#  second is to derive bounding boxes of the text.\n",
    "\n",
    "layerNames = [\"feature_fusion/Conv_7/Sigmoid\",\"feature_fusion/concat_3\"]\n",
    "east_text_detector = cv2.dnn.readNet(\"frozen_east_text_detection.pb\")\n",
    "print(\"EAST text detector loaded :  \", east_text_detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a blob from the image to forward pass it to EAST model\n",
    "blob = cv2.dnn.blobFromImage(image=resized_image,\n",
    "                             scalefactor=1.0,\n",
    "                             size=(new_width, new_height),\n",
    "                             mean=(123.68, 116.78, 103.94),\n",
    "                             swapRB=True,crop=False)\n",
    "\n",
    "print(\"Blob shape ----> \", blob.shape, blob.dtype)\n",
    "print(\"resized_image shape ----> \", resized_image.shape, resized_image.dtype)\n",
    "east_text_detector.setInput(blob)\n",
    "(scores, geometry) = east_text_detector.forward(layerNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scores contains the probability of the region containing the text\n",
    "print(scores.shape, scores.ndim, scores.shape[2:4])\n",
    "# For the box co-ordinates of the text\n",
    "print(geometry.shape, geometry.ndim, geometry.shape[2:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_text_predictions(scores, geometry):\n",
    "    rows,cols = scores.shape[2:4]\n",
    "    min_confidence = 0.5\n",
    "    rects = []\n",
    "    confidences = []\n",
    "\n",
    "    for y in range(0, rows):\n",
    "        # extract the scores (probabilities), followed by the geometrical\n",
    "        # data used to derive potential bounding box coordinates that\n",
    "        # surround text\n",
    "        scoresData = scores[0, 0, y]\n",
    "        xData0 = geometry[0, 0, y]\n",
    "        xData1 = geometry[0, 1, y]\n",
    "        xData2 = geometry[0, 2, y]\n",
    "        xData3 = geometry[0, 3, y]\n",
    "        anglesData = geometry[0, 4, y]\n",
    "        # loop over the number of columns\n",
    "        for x in range(0, cols):\n",
    "            # if our score does not have sufficient probability, ignore it\n",
    "            if scoresData[x] < min_confidence:\n",
    "                continue\n",
    "            # compute the offset factor as our resulting feature maps will\n",
    "            # be 4x smaller than the input image\n",
    "            (offsetX, offsetY) = (x * 4.0, y * 4.0)\n",
    "            # extract the rotation angle for the prediction and then\n",
    "            # compute the sin and cosine\n",
    "            angle = anglesData[x]\n",
    "            cos = np.cos(angle)\n",
    "            sin = np.sin(angle)\n",
    "            # use the geometry volume to derive the width and height of\n",
    "            # the bounding box\n",
    "            h = xData0[x] + xData2[x]\n",
    "            w = xData1[x] + xData3[x]\n",
    "            # compute both the starting and ending (x, y)-coordinates for\n",
    "            #  the text prediction bounding box\n",
    "            endX = int(offsetX + (cos * xData1[x]) + (sin * xData2[x]))\n",
    "            endY = int(offsetY - (sin * xData1[x]) + (cos * xData2[x]))\n",
    "            startX = int(endX - w)\n",
    "            startY = int(endY - h)\n",
    "            # add the bounding box coordinates and probability score to\n",
    "            # our respective lists\n",
    "            rects.append((startX, startY, endX, endY))\n",
    "            confidences.append(scoresData[x])\n",
    "    return (rects, confidences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rects, confidences =  decode_text_predictions(scores, geometry)\n",
    "# apply non-maxima suppression to suppress weak, overlapping bounding boxes\n",
    "boxes = non_max_suppression(np.array(rects), probs=confidences)\n",
    "# loop over the bounding boxes\n",
    "for (startX, startY, endX, endY) in boxes:\n",
    "    # scale the bounding box coordinates based on the respective\n",
    "    # ratios\n",
    "    startX = int(startX * width_ratio)\n",
    "    startY = int(startY * heigth_ratio)\n",
    "    endX = int(endX * width_ratio)\n",
    "    endY = int(endY * heigth_ratio)\n",
    "    # draw the bounding box on the image\n",
    "    cv2.rectangle(base_image, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "cv2.imshow(\"Text Detection\", base_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now for live video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imutils.video import VideoStream\n",
    "(W, H) = (None, None)\n",
    "(newW, newH) = (480,640)\n",
    "(rW, rH) = (None, None)\n",
    "# vs = VideoStream(src=0).start()\n",
    "cap = cv2.VideoCapture(0)\n",
    "i = 0\n",
    "cv2.namedWindow(\"Realtime\", cv2.WINDOW_NORMAL) # to create an window and then populate it with the image\n",
    "\n",
    "while True:\n",
    "    # grab the current frame, then handle if we are using a\n",
    "    # VideoStream or VideoCapture object\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow(\"Realtime\", frame) \n",
    "    cv2.waitKey(0)\n",
    "    # frame = frame[1] # if args.get(\"video\", False) else frame\n",
    "    # check to see if we have reached the end of the stream\n",
    "    if not ret:\n",
    "        break\n",
    "    print(\"Source Frame shape ,\", frame.shape, frame.dtype)\n",
    "    # resize the frame, maintaining the aspect ratio\n",
    "    # frame = imutils.resize(frame, width=960)\n",
    "    # orig = frame.copy()\n",
    "    # if our frame dimensions are None, we still need to compute the\n",
    "    # ratio of old frame dimensions to new frame dimensions\n",
    "    #if W is None or H is None:\n",
    "    #    (H, W) = frame.shape[:2]\n",
    "    #    rW = W / float(newW)\n",
    "    #    rH = H / float(newH)\n",
    "    # resize the frame, this time ignoring aspect ratio\n",
    "    # frame = cv2.resize(frame, (newW, newH))\n",
    "    print(frame.shape, newW,newH,frame.dtype)\n",
    "    frame_blob = cv2.dnn.blobFromImage(frame, 1.0, (newW, newH), (123.68, 116.78, 103.94), swapRB=True, crop=False)\n",
    "    print(\"Blob shape ---->\", frame_blob.shape, frame_blob.dtype)\n",
    "    east_text_detector.setInput(frame_blob)\n",
    "    try:\n",
    "        (scores, geometry) = east_text_detector.forward(layerNames)\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        continue\n",
    "    # decode the predictions, then  apply non-maxima suppression to\n",
    "    # suppress weak, overlapping bounding boxes\n",
    "    (rects, confidences) = decode_text_predictions(scores, geometry)\n",
    "    boxes = non_max_suppression(np.array(rects), probs=confidences)\n",
    "    # loop over the bounding boxes\n",
    "    for (startX, startY, endX, endY) in boxes:\n",
    "        # scale the bounding box coordinates based on the respective\n",
    "        # ratios\n",
    "        startX = int(startX * rW)\n",
    "        startY = int(startY * rH)\n",
    "        endX = int(endX * rW)\n",
    "        endY = int(endY * rH)\n",
    "        # draw the bounding box on the frame\n",
    "        cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "    \n",
    "    cv2.imshow(\"Realtime\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    # if the `q` key was pressed, break from the loop\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
